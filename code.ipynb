{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whisper Demonstration Notebook using OpenAI's Whisper Implementation with GPU Support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torch\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Check for GPU Availability and Load the Whisper Model on GPU if Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model = whisper.load_model(\"turbo\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Define Function to Load and Transcribe Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(file_path):\n",
    "    \"\"\"\n",
    "    Load the audio with librosa, convert to 16kHz, and transcribe using Whisper.\n",
    "    \"\"\"\n",
    "    # Load audio file and resample to 16kHz\n",
    "    audio, sr = librosa.load(file_path, sr=16000)\n",
    "    \n",
    "    # Convert audio to the tensor format Whisper expects and move it to the GPU if available\n",
    "    audio_tensor = torch.tensor(audio).to(device)\n",
    "    \n",
    "    # Transcribe the audio tensor\n",
    "    result = model.transcribe(audio_tensor)\n",
    "    transcription = result['text']\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Define Function to Translate Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_audio(file_path, target_language=\"de\"):  # For example, 'de' for German\n",
    "    \"\"\"\n",
    "    Load the audio with librosa, convert to 16kHz, and translate using Whisper.\n",
    "    \"\"\"\n",
    "    # Load audio file and resample to 16kHz\n",
    "    audio, sr = librosa.load(file_path, sr=16000)\n",
    "    \n",
    "    # Convert audio to the tensor format Whisper expects and move it to the GPU if available\n",
    "    audio_tensor = torch.tensor(audio).to(device)\n",
    "    \n",
    "    # Translate the audio tensor by setting the task to 'translate'\n",
    "    result = model.transcribe(audio_tensor, task=\"translate\", language=target_language)\n",
    "    translation = result['text']\n",
    "    return translation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First demo: Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Recording.wav\"\n",
    "# Transcription\n",
    "try:\n",
    "    transcription = transcribe_audio(file_path)\n",
    "    print(\"Transcription:\", transcription)\n",
    "except Exception as e:\n",
    "    print(\"Error during transcription:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second demo: Transcribing and translating from Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Recording_zh.wav\"\n",
    "# Translation\n",
    "try:\n",
    "    target_language = \"en\"  # e.g., 'fr' for French, 'es' for Spanish\n",
    "    transcription = transcribe_audio(file_path)\n",
    "    print(\"Transcription:\", transcription)\n",
    "    translation = translate_audio(file_path, target_language)\n",
    "    print(f\"Translation ({target_language}):\", translation)\n",
    "except Exception as e:\n",
    "    print(\"Error during translation:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
